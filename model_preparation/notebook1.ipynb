{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Download dataset and save it in the project location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"bhargavchirumamilla/thyroid-cancer-risk-dataset\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.rename(path, \"./download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./download/thyroid_cancer_risk_data.csv\")\n",
    "df.dropna()\n",
    "df = df.drop(\"Country\", axis=1)\n",
    "df = pd.get_dummies(df, columns=[\"Gender\", \"Ethnicity\", \"Smoking\", \"Obesity\", \"Diabetes\", \"Family_History\", \"Radiation_Exposure\", \"Iodine_Deficiency\"] , dtype=float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a balanced dataset\n",
    "\n",
    "df_benign = df[df[\"Diagnosis\"] == \"Benign\"]\n",
    "df_benign =df_benign.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "df_malignant = df[df[\"Diagnosis\"]==\"Malignant\"]\n",
    "df_malignant = df_malignant.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "df = df_benign[:49000]\n",
    "df = pd.concat((df, df_malignant[:49000]), axis=0)\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98000, 2)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_risk = df[\"Thyroid_Cancer_Risk\"]\n",
    "y_risk = pd.get_dummies(y_risk)\n",
    "y_diagnosis = df[\"Diagnosis\"]\n",
    "y_diagnosis = pd.get_dummies(y_diagnosis, dtype=float)\n",
    "\n",
    "\n",
    "df = df.drop([\"Thyroid_Cancer_Risk\", \"Diagnosis\", \"Patient_ID\"], axis=1)\n",
    "\n",
    "y = y_diagnosis.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                         0.89\n",
       "TSH_Level                   1.00\n",
       "T3_Level                    1.00\n",
       "T4_Level                    1.00\n",
       "Nodule_Size                 1.00\n",
       "Gender_Female               1.00\n",
       "Gender_Male                 1.00\n",
       "Ethnicity_African           1.00\n",
       "Ethnicity_Asian             1.00\n",
       "Ethnicity_Caucasian         1.00\n",
       "Ethnicity_Hispanic          1.00\n",
       "Ethnicity_Middle Eastern    1.00\n",
       "Smoking_No                  1.00\n",
       "Smoking_Yes                 1.00\n",
       "Obesity_No                  1.00\n",
       "Obesity_Yes                 1.00\n",
       "Diabetes_No                 1.00\n",
       "Diabetes_Yes                1.00\n",
       "Family_History_No           1.00\n",
       "Family_History_Yes          1.00\n",
       "Radiation_Exposure_No       1.00\n",
       "Radiation_Exposure_Yes      1.00\n",
       "Iodine_Deficiency_No        1.00\n",
       "Iodine_Deficiency_Yes       1.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Age\"] = df[\"Age\"]/100\n",
    "df[\"TSH_Level\"] = df[\"TSH_Level\"]/10\n",
    "df[\"T3_Level\"] = df[\"T3_Level\"]/3.5\n",
    "df[\"T4_Level\"] = df[\"T4_Level\"]/12\n",
    "df[\"Nodule_Size\"] = df[\"Nodule_Size\"]/5\n",
    "\n",
    "df.max(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "Age max = 89, I divide by 100, will set later max value to 100,\n",
    "\n",
    "TSH_Level max = 10, -> divide by 10 \n",
    "\n",
    "T3_Level max = 3.5 -> divide by 3.5\n",
    "\n",
    "T4_Level max = 12 -> divide by 12\n",
    "\n",
    "Nodule_Size max = 5 -> divide by 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = df.values\n",
    "X = np.float32(X)\n",
    "y = np.float32(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare data for prediction of diagnosis\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Solving with decision Tree\n",
    "\n",
    "- 63.9% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6495918367346939"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(criterion=\"gini\", splitter=\"best\", max_depth=11)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Solving with neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThyroidCancerModel(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=24, out_features=512, bias=True)\n",
       "    (1): Dropout(p=0.2, inplace=False)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=512, out_features=16, bias=True)\n",
       "    (4): Dropout(p=0.2, inplace=False)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class ThyroidCancerModel(torch.nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=24, out_features=512),\n",
    "            torch.nn.Dropout(p=0.2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=512, out_features=16),\n",
    "            torch.nn.Dropout(p=0.2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=16, out_features=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "model2 = ThyroidCancerModel()\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params = model2.parameters(), lr= 0.0001)\n",
    "lossfn = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1125],\n",
       "        [-0.1014],\n",
       "        [-0.1517],\n",
       "        ...,\n",
       "        [-0.0991],\n",
       "        [-0.1022],\n",
       "        [-0.1266]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating tensors\n",
    "\n",
    "X_train_t = torch.from_numpy(X_train).to(device=\"cuda\")\n",
    "X_test_t = torch.from_numpy(X_test).to(device=\"cuda\")\n",
    "\n",
    "y_train_t = torch.from_numpy(y_train).to(device=\"cuda\")\n",
    "y_train_t = torch.argmax(y_train_t, dim=1)\n",
    "y_train_t = y_train_t.unsqueeze(dim=1).float()\n",
    "\n",
    "y_test_t = torch.from_numpy(y_test).to(device=\"cuda\")\n",
    "y_test_t = torch.argmax(y_test_t, dim=1)\n",
    "y_test_t = y_test_t.unsqueeze(dim=1).float()\n",
    "\n",
    "model2 = model2.to(device=\"cuda\")\n",
    "\n",
    "model2(X_train_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=[\"epoch\", \"training_loss\", \"testing_loss\", \"test_accuracy\", \"test_precision\", \"test_recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "from torchmetrics import Precision\n",
    "from torchmetrics import Recall\n",
    "\n",
    "accuracy = Accuracy(task=\"binary\").to(device=\"cuda\")\n",
    "precision = Precision(task=\"binary\").to(device=\"cuda\")\n",
    "recall = Recall(task=\"binary\").to(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 | loss: 0.6943337321281433 | test_loss: 0.693591296672821 | accuracy: 0.5026530623435974 | precision: 0.0 | recall:0.0\n",
      "epoch:100 | loss: 0.6641370058059692 | test_loss: 0.6630702614784241 | accuracy: 0.6310204267501831 | precision: 0.657960832118988 | recall:0.5375461578369141\n",
      "epoch:200 | loss: 0.6458232998847961 | test_loss: 0.6438403129577637 | accuracy: 0.631428599357605 | precision: 0.6637259721755981 | recall:0.5248256325721741\n",
      "epoch:300 | loss: 0.6317735314369202 | test_loss: 0.6283706426620483 | accuracy: 0.640816330909729 | precision: 0.685479462146759 | recall:0.5133360624313354\n",
      "epoch:400 | loss: 0.6216685175895691 | test_loss: 0.6172463893890381 | accuracy: 0.6499999761581421 | precision: 0.6856995820999146 | recall:0.5469840168952942\n",
      "epoch:500 | loss: 0.6183153390884399 | test_loss: 0.6121488213539124 | accuracy: 0.6587755084037781 | precision: 0.6936708688735962 | recall:0.5621665716171265\n",
      "epoch:600 | loss: 0.6161653399467468 | test_loss: 0.610205352306366 | accuracy: 0.6585714221000671 | precision: 0.6933198571205139 | recall:0.5621665716171265\n",
      "epoch:700 | loss: 0.6150726675987244 | test_loss: 0.6095212697982788 | accuracy: 0.6593877673149109 | precision: 0.6947261691093445 | recall:0.5621665716171265\n",
      "epoch:800 | loss: 0.6143577098846436 | test_loss: 0.6092326641082764 | accuracy: 0.6587755084037781 | precision: 0.6952526569366455 | recall:0.5588838458061218\n",
      "epoch:900 | loss: 0.6143954992294312 | test_loss: 0.6091481447219849 | accuracy: 0.6583673357963562 | precision: 0.695540726184845 | recall:0.5568321943283081\n",
      "epoch:1000 | loss: 0.6139281392097473 | test_loss: 0.6090827584266663 | accuracy: 0.6581632494926453 | precision: 0.6955851912498474 | recall:0.5560114979743958\n",
      "epoch:1100 | loss: 0.613988995552063 | test_loss: 0.6090454459190369 | accuracy: 0.6583673357963562 | precision: 0.696345865726471 | recall:0.5551908016204834\n",
      "epoch:1200 | loss: 0.6133702397346497 | test_loss: 0.6090368032455444 | accuracy: 0.6583673357963562 | precision: 0.6965481638908386 | recall:0.5547804832458496\n",
      "epoch:1300 | loss: 0.6136254668235779 | test_loss: 0.6090205311775208 | accuracy: 0.6581632494926453 | precision: 0.6965944170951843 | recall:0.5539597868919373\n",
      "epoch:1400 | loss: 0.6131004095077515 | test_loss: 0.6090332269668579 | accuracy: 0.658979594707489 | precision: 0.6978305578231812 | recall:0.554370105266571\n",
      "epoch:1500 | loss: 0.6132160425186157 | test_loss: 0.609041690826416 | accuracy: 0.6597959399223328 | precision: 0.6992753744125366 | recall:0.554370105266571\n",
      "epoch:1600 | loss: 0.6133374571800232 | test_loss: 0.6090940833091736 | accuracy: 0.658979594707489 | precision: 0.6994791626930237 | recall:0.5510873794555664\n",
      "epoch:1700 | loss: 0.6129725575447083 | test_loss: 0.609086275100708 | accuracy: 0.6595918536186218 | precision: 0.7001561522483826 | recall:0.5519080758094788\n",
      "epoch:1800 | loss: 0.6128693222999573 | test_loss: 0.6091343760490417 | accuracy: 0.6591836810112 | precision: 0.7000521421432495 | recall:0.5506770610809326\n",
      "epoch:1900 | loss: 0.6127316951751709 | test_loss: 0.6091765761375427 | accuracy: 0.6595918536186218 | precision: 0.7014143466949463 | recall:0.5494460463523865\n",
      "epoch:2000 | loss: 0.6119970083236694 | test_loss: 0.6091828942298889 | accuracy: 0.6591836810112 | precision: 0.7015239000320435 | recall:0.5478046536445618\n",
      "epoch:2100 | loss: 0.6121999621391296 | test_loss: 0.6092269420623779 | accuracy: 0.6587755084037781 | precision: 0.7005768418312073 | recall:0.5482150316238403\n",
      "epoch:2200 | loss: 0.6126434803009033 | test_loss: 0.609259843826294 | accuracy: 0.6595918536186218 | precision: 0.7016255855560303 | recall:0.5490357279777527\n",
      "epoch:2300 | loss: 0.6122111082077026 | test_loss: 0.609292209148407 | accuracy: 0.6597959399223328 | precision: 0.7030590772628784 | recall:0.5469840168952942\n",
      "epoch:2400 | loss: 0.6118626594543457 | test_loss: 0.6093668341636658 | accuracy: 0.6591836810112 | precision: 0.7021613121032715 | recall:0.5465736389160156\n",
      "epoch:2500 | loss: 0.6119093894958496 | test_loss: 0.6093930602073669 | accuracy: 0.6593877673149109 | precision: 0.702531635761261 | recall:0.5465736389160156\n",
      "epoch:2600 | loss: 0.6121242642402649 | test_loss: 0.6094234585762024 | accuracy: 0.6583673357963562 | precision: 0.7019587159156799 | recall:0.5441116094589233\n",
      "epoch:2700 | loss: 0.6116454005241394 | test_loss: 0.6094211935997009 | accuracy: 0.6585714221000671 | precision: 0.7031915187835693 | recall:0.5424702763557434\n",
      "epoch:2800 | loss: 0.6114581823348999 | test_loss: 0.6094452738761902 | accuracy: 0.6593877673149109 | precision: 0.7046908140182495 | recall:0.5424702763557434\n",
      "epoch:2900 | loss: 0.6112791299819946 | test_loss: 0.6095147132873535 | accuracy: 0.6591836810112 | precision: 0.7043154239654541 | recall:0.5424702763557434\n",
      "epoch:3000 | loss: 0.6113245487213135 | test_loss: 0.6095280647277832 | accuracy: 0.658979594707489 | precision: 0.7050321102142334 | recall:0.5404185652732849\n",
      "epoch:3100 | loss: 0.6113811731338501 | test_loss: 0.6095763444900513 | accuracy: 0.658979594707489 | precision: 0.7050321102142334 | recall:0.5404185652732849\n",
      "epoch:3200 | loss: 0.6117673516273499 | test_loss: 0.6095585823059082 | accuracy: 0.6583673357963562 | precision: 0.704119861125946 | recall:0.5400081872940063\n",
      "epoch:3300 | loss: 0.6109567284584045 | test_loss: 0.609602153301239 | accuracy: 0.6593877673149109 | precision: 0.7062298655509949 | recall:0.5395978689193726\n",
      "epoch:3400 | loss: 0.6105771660804749 | test_loss: 0.6095764636993408 | accuracy: 0.6587755084037781 | precision: 0.7053139805793762 | recall:0.5391875505447388\n",
      "epoch:3500 | loss: 0.6110628247261047 | test_loss: 0.6095693111419678 | accuracy: 0.6587755084037781 | precision: 0.7066450715065002 | recall:0.5367254614830017\n",
      "epoch:3600 | loss: 0.6107629537582397 | test_loss: 0.609579861164093 | accuracy: 0.6585714221000671 | precision: 0.7060409784317017 | recall:0.5371358394622803\n",
      "epoch:3700 | loss: 0.6112014651298523 | test_loss: 0.6096056699752808 | accuracy: 0.6579591631889343 | precision: 0.7064568400382996 | recall:0.5342634320259094\n",
      "epoch:3800 | loss: 0.6104082465171814 | test_loss: 0.6096618175506592 | accuracy: 0.6587755084037781 | precision: 0.7070925831794739 | recall:0.5359048247337341\n",
      "epoch:3900 | loss: 0.6109136939048767 | test_loss: 0.6096291542053223 | accuracy: 0.6581632494926453 | precision: 0.7061688303947449 | recall:0.5354944467544556\n",
      "epoch:4000 | loss: 0.6102349758148193 | test_loss: 0.6096648573875427 | accuracy: 0.6565306186676025 | precision: 0.7060109376907349 | recall:0.5301600098609924\n",
      "epoch:4100 | loss: 0.6102452874183655 | test_loss: 0.6096410155296326 | accuracy: 0.6587755084037781 | precision: 0.7084468603134155 | recall:0.5334427356719971\n",
      "epoch:4200 | loss: 0.6104488968849182 | test_loss: 0.6096725463867188 | accuracy: 0.6569387912750244 | precision: 0.7070098519325256 | recall:0.5297496914863586\n",
      "epoch:4300 | loss: 0.6105571985244751 | test_loss: 0.6096657514572144 | accuracy: 0.6581632494926453 | precision: 0.7088815569877625 | recall:0.530570387840271\n",
      "epoch:4400 | loss: 0.6100428104400635 | test_loss: 0.60970139503479 | accuracy: 0.6577550768852234 | precision: 0.7090209126472473 | recall:0.5289289951324463\n",
      "epoch:4500 | loss: 0.6105107069015503 | test_loss: 0.6097428202629089 | accuracy: 0.6569387912750244 | precision: 0.7088397741317749 | recall:0.526466965675354\n",
      "epoch:4600 | loss: 0.6094906330108643 | test_loss: 0.6098045706748962 | accuracy: 0.6579591631889343 | precision: 0.7089511156082153 | recall:0.5297496914863586\n",
      "epoch:4700 | loss: 0.6097586154937744 | test_loss: 0.6097937226295471 | accuracy: 0.6571428775787354 | precision: 0.7090005278587341 | recall:0.5268772840499878\n",
      "epoch:4800 | loss: 0.6102189421653748 | test_loss: 0.6098316311836243 | accuracy: 0.6581632494926453 | precision: 0.7114317417144775 | recall:0.5260566473007202\n",
      "epoch:4900 | loss: 0.6100589036941528 | test_loss: 0.6098707318305969 | accuracy: 0.6579591631889343 | precision: 0.7105699777603149 | recall:0.5268772840499878\n",
      "epoch:5000 | loss: 0.609473466873169 | test_loss: 0.6098732352256775 | accuracy: 0.6591836810112 | precision: 0.7122302055358887 | recall:0.5281083583831787\n",
      "epoch:5100 | loss: 0.6094589829444885 | test_loss: 0.6098369359970093 | accuracy: 0.6595918536186218 | precision: 0.7130193710327148 | recall:0.5281083583831787\n",
      "epoch:5200 | loss: 0.6101356744766235 | test_loss: 0.6098405718803406 | accuracy: 0.6602040529251099 | precision: 0.7151616215705872 | recall:0.526466965675354\n",
      "epoch:5300 | loss: 0.6094396114349365 | test_loss: 0.6098355054855347 | accuracy: 0.6600000262260437 | precision: 0.7162086367607117 | recall:0.5240049362182617\n",
      "epoch:5400 | loss: 0.6094831228256226 | test_loss: 0.60980623960495 | accuracy: 0.6604081392288208 | precision: 0.7162842750549316 | recall:0.5252359509468079\n",
      "epoch:5500 | loss: 0.6089087128639221 | test_loss: 0.609825074672699 | accuracy: 0.6597959399223328 | precision: 0.7150837779045105 | recall:0.5252359509468079\n",
      "epoch:5600 | loss: 0.609386146068573 | test_loss: 0.6098570823669434 | accuracy: 0.6591836810112 | precision: 0.7155705690383911 | recall:0.522363543510437\n",
      "epoch:5700 | loss: 0.6090486645698547 | test_loss: 0.6097801327705383 | accuracy: 0.6600000262260437 | precision: 0.7157247066497803 | recall:0.5248256325721741\n",
      "epoch:5800 | loss: 0.609568178653717 | test_loss: 0.6098523736000061 | accuracy: 0.6606122255325317 | precision: 0.7174157500267029 | recall:0.5240049362182617\n",
      "epoch:5900 | loss: 0.608698308467865 | test_loss: 0.609824001789093 | accuracy: 0.6597959399223328 | precision: 0.7165354490280151 | recall:0.5227739214897156\n",
      "epoch:6000 | loss: 0.6100659966468811 | test_loss: 0.6099228858947754 | accuracy: 0.6604081392288208 | precision: 0.7179921269416809 | recall:0.522363543510437\n",
      "epoch:6100 | loss: 0.6087015271186829 | test_loss: 0.6098138689994812 | accuracy: 0.6604081392288208 | precision: 0.7182382941246033 | recall:0.5219532251358032\n",
      "epoch:6200 | loss: 0.6087763905525208 | test_loss: 0.6098530292510986 | accuracy: 0.6606122255325317 | precision: 0.716928243637085 | recall:0.5248256325721741\n",
      "epoch:6300 | loss: 0.6091870069503784 | test_loss: 0.60988450050354 | accuracy: 0.6602040529251099 | precision: 0.7185730338096619 | recall:0.5207222104072571\n",
      "epoch:6400 | loss: 0.608648419380188 | test_loss: 0.6099022626876831 | accuracy: 0.6612244844436646 | precision: 0.7188732624053955 | recall:0.5235945582389832\n",
      "epoch:6500 | loss: 0.6089155673980713 | test_loss: 0.610023021697998 | accuracy: 0.6602040529251099 | precision: 0.7178329825401306 | recall:0.5219532251358032\n",
      "epoch:6600 | loss: 0.6082836389541626 | test_loss: 0.6099517941474915 | accuracy: 0.6604081392288208 | precision: 0.7187322974205017 | recall:0.5211325287818909\n",
      "epoch:6700 | loss: 0.6089338064193726 | test_loss: 0.6099727749824524 | accuracy: 0.6620408296585083 | precision: 0.7195053696632385 | recall:0.5252359509468079\n",
      "epoch:6800 | loss: 0.6091499328613281 | test_loss: 0.6099499464035034 | accuracy: 0.6614285707473755 | precision: 0.7215262055397034 | recall:0.5199015140533447\n",
      "epoch:6900 | loss: 0.6083245873451233 | test_loss: 0.6099449396133423 | accuracy: 0.6614285707473755 | precision: 0.7205215692520142 | recall:0.5215429067611694\n",
      "epoch:7000 | loss: 0.6084384918212891 | test_loss: 0.6100162863731384 | accuracy: 0.6620408296585083 | precision: 0.7207461595535278 | recall:0.5231842398643494\n",
      "epoch:7100 | loss: 0.607909619808197 | test_loss: 0.6100835204124451 | accuracy: 0.6610203981399536 | precision: 0.7199546694755554 | recall:0.5211325287818909\n",
      "epoch:7200 | loss: 0.6083913445472717 | test_loss: 0.610023021697998 | accuracy: 0.6606122255325317 | precision: 0.7206385135650635 | recall:0.5186704993247986\n",
      "epoch:7300 | loss: 0.6077656745910645 | test_loss: 0.6101348996162415 | accuracy: 0.6612244844436646 | precision: 0.7208641171455383 | recall:0.5203118324279785\n",
      "epoch:7400 | loss: 0.6080763339996338 | test_loss: 0.6101493835449219 | accuracy: 0.6602040529251099 | precision: 0.7213302850723267 | recall:0.5162084698677063\n",
      "epoch:7500 | loss: 0.6081611514091492 | test_loss: 0.6101096272468567 | accuracy: 0.6608163118362427 | precision: 0.7220630645751953 | recall:0.5170291066169739\n",
      "epoch:7600 | loss: 0.6075785756111145 | test_loss: 0.6101555228233337 | accuracy: 0.6620408296585083 | precision: 0.7227609753608704 | recall:0.5199015140533447\n",
      "epoch:7700 | loss: 0.607093334197998 | test_loss: 0.6101168990135193 | accuracy: 0.6606122255325317 | precision: 0.7221584320068359 | recall:0.5162084698677063\n",
      "epoch:7800 | loss: 0.6076697707176208 | test_loss: 0.6101790070533752 | accuracy: 0.6616326570510864 | precision: 0.7229536175727844 | recall:0.5182601809501648\n",
      "epoch:7900 | loss: 0.6069662570953369 | test_loss: 0.61019366979599 | accuracy: 0.6614285707473755 | precision: 0.7222856879234314 | recall:0.5186704993247986\n",
      "epoch:8000 | loss: 0.6079174280166626 | test_loss: 0.610291600227356 | accuracy: 0.6610203981399536 | precision: 0.7232450842857361 | recall:0.5157980918884277\n",
      "epoch:8100 | loss: 0.60769122838974 | test_loss: 0.6103456020355225 | accuracy: 0.6618367433547974 | precision: 0.7231121063232422 | recall:0.5186704993247986\n",
      "epoch:8200 | loss: 0.6076475381851196 | test_loss: 0.6102993488311768 | accuracy: 0.6608163118362427 | precision: 0.7228292226791382 | recall:0.5157980918884277\n",
      "epoch:8300 | loss: 0.6069605946540833 | test_loss: 0.6103216409683228 | accuracy: 0.6606122255325317 | precision: 0.7216494679450989 | recall:0.5170291066169739\n",
      "epoch:8400 | loss: 0.6072537302970886 | test_loss: 0.6103635430335999 | accuracy: 0.6612244844436646 | precision: 0.7226361036300659 | recall:0.5174394845962524\n",
      "epoch:8500 | loss: 0.6073440313339233 | test_loss: 0.6103524565696716 | accuracy: 0.6606122255325317 | precision: 0.7219036817550659 | recall:0.5166187882423401\n",
      "epoch:8600 | loss: 0.6072078347206116 | test_loss: 0.6103969216346741 | accuracy: 0.6610203981399536 | precision: 0.7235022783279419 | recall:0.515387773513794\n",
      "epoch:8700 | loss: 0.606959879398346 | test_loss: 0.6105039715766907 | accuracy: 0.6608163118362427 | precision: 0.7228292226791382 | recall:0.5157980918884277\n",
      "epoch:8800 | loss: 0.607108473777771 | test_loss: 0.6104861497879028 | accuracy: 0.6612244844436646 | precision: 0.723661482334137 | recall:0.5157980918884277\n",
      "epoch:8900 | loss: 0.6073628664016724 | test_loss: 0.6104874610900879 | accuracy: 0.6610203981399536 | precision: 0.722988486289978 | recall:0.5162084698677063\n",
      "epoch:9000 | loss: 0.6068133115768433 | test_loss: 0.6104865670204163 | accuracy: 0.6612244844436646 | precision: 0.7239193320274353 | recall:0.515387773513794\n",
      "epoch:9100 | loss: 0.6070576310157776 | test_loss: 0.6105958819389343 | accuracy: 0.6610203981399536 | precision: 0.722988486289978 | recall:0.5162084698677063\n",
      "epoch:9200 | loss: 0.6066620349884033 | test_loss: 0.6105988621711731 | accuracy: 0.6604081392288208 | precision: 0.7235395908355713 | recall:0.5133360624313354\n",
      "epoch:9300 | loss: 0.606524646282196 | test_loss: 0.6106728911399841 | accuracy: 0.6602040529251099 | precision: 0.7228637337684631 | recall:0.5137463808059692\n",
      "epoch:9400 | loss: 0.6069864630699158 | test_loss: 0.6106489300727844 | accuracy: 0.6606122255325317 | precision: 0.7234411239624023 | recall:0.5141567587852478\n",
      "epoch:9500 | loss: 0.6066283583641052 | test_loss: 0.6107298731803894 | accuracy: 0.6610203981399536 | precision: 0.7235022783279419 | recall:0.515387773513794\n",
      "epoch:9600 | loss: 0.6065820455551147 | test_loss: 0.6107868552207947 | accuracy: 0.6616326570510864 | precision: 0.7239792943000793 | recall:0.5166187882423401\n",
      "epoch:9700 | loss: 0.6062225103378296 | test_loss: 0.6107959151268005 | accuracy: 0.6612244844436646 | precision: 0.7231476306915283 | recall:0.5166187882423401\n",
      "epoch:9800 | loss: 0.6060084104537964 | test_loss: 0.6108667254447937 | accuracy: 0.6616326570510864 | precision: 0.7255356311798096 | recall:0.5141567587852478\n",
      "epoch:9900 | loss: 0.6066523194313049 | test_loss: 0.6108944416046143 | accuracy: 0.6624490022659302 | precision: 0.7253885865211487 | recall:0.5170291066169739\n",
      "epoch:10000 | loss: 0.6065034866333008 | test_loss: 0.6108863949775696 | accuracy: 0.6616326570510864 | precision: 0.7244956493377686 | recall:0.5157980918884277\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "epochs = 10001\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model2.train()\n",
    "    logits = model2(X_train_t)\n",
    "    loss = lossfn(logits, y_train_t)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        model2.eval()\n",
    "        with torch.inference_mode():\n",
    "            test_logits = model2(X_test_t)\n",
    "            test_loss = lossfn(test_logits, y_test_t)\n",
    "            \n",
    "            res = torch.sigmoid(test_logits)\n",
    "            res = (res > 0.5).int()\n",
    "            \n",
    "            ac = accuracy(res, y_test_t)\n",
    "            pc = precision(res, y_test_t)\n",
    "            rc = recall(res, y_test_t)\n",
    "            \n",
    "            results.loc[len(results)] = [epoch, loss.item(), test_loss.item(), ac.item(), pc.item(), rc.item()]\n",
    "            \n",
    "            print(F\"epoch:{epoch} | loss: {loss.item()} | test_loss: {test_loss.item()} | accuracy: {ac.item()} | precision: {pc.item()} | recall:{rc.item()}\")\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.scatter(y=results[\"test_accuracy\"].values, x=results[\"epoch\"].values)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
